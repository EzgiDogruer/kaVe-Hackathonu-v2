{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>calorie</th>\n",
       "      <th>water</th>\n",
       "      <th>carbohydrate</th>\n",
       "      <th>fiber</th>\n",
       "      <th>sugar</th>\n",
       "      <th>protein</th>\n",
       "      <th>fat</th>\n",
       "      <th>sfat</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>...</th>\n",
       "      <th>iron</th>\n",
       "      <th>folat</th>\n",
       "      <th>pantotenik</th>\n",
       "      <th>fosfor</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>cinko</th>\n",
       "      <th>copper</th>\n",
       "      <th>selenium</th>\n",
       "      <th>manganese</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>717</td>\n",
       "      <td>17.94</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.85</td>\n",
       "      <td>81.11</td>\n",
       "      <td>51.368</td>\n",
       "      <td>215</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>3</td>\n",
       "      <td>0.11</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>0.09</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Hayvansal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>116</td>\n",
       "      <td>76.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.41</td>\n",
       "      <td>3.71</td>\n",
       "      <td>94.900.000</td>\n",
       "      <td>89</td>\n",
       "      <td>...</td>\n",
       "      <td>0.76</td>\n",
       "      <td>4</td>\n",
       "      <td>1.1</td>\n",
       "      <td>174</td>\n",
       "      <td>20</td>\n",
       "      <td>02.05</td>\n",
       "      <td>66</td>\n",
       "      <td>21.8</td>\n",
       "      <td>14</td>\n",
       "      <td>Hayvansal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>75</td>\n",
       "      <td>79.53</td>\n",
       "      <td>17.99</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.59</td>\n",
       "      <td>67</td>\n",
       "      <td>60.000.000</td>\n",
       "      <td>71</td>\n",
       "      <td>29</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.8</td>\n",
       "      <td>56.000.000</td>\n",
       "      <td>Bitkisel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>132.46</td>\n",
       "      <td>73.13</td>\n",
       "      <td>12.46</td>\n",
       "      <td>1.59</td>\n",
       "      <td>1.59</td>\n",
       "      <td>6.37</td>\n",
       "      <td>6.57</td>\n",
       "      <td>2.23</td>\n",
       "      <td>22.57</td>\n",
       "      <td>...</td>\n",
       "      <td>0.98</td>\n",
       "      <td>15.53</td>\n",
       "      <td>0.39</td>\n",
       "      <td>79.5</td>\n",
       "      <td>21.38</td>\n",
       "      <td>1.36</td>\n",
       "      <td>0.15</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0.24</td>\n",
       "      <td>Mix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>103.29</td>\n",
       "      <td>79.04</td>\n",
       "      <td>04.01</td>\n",
       "      <td>01.07</td>\n",
       "      <td>2.38</td>\n",
       "      <td>11.47</td>\n",
       "      <td>4.53</td>\n",
       "      <td>0.77</td>\n",
       "      <td>28.62</td>\n",
       "      <td>...</td>\n",
       "      <td>0.71</td>\n",
       "      <td>15.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>78.47</td>\n",
       "      <td>16.49</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.05</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Hayvansal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID calorie  water carbohydrate  fiber sugar protein    fat        sfat  \\\n",
       "0   0     717  17.94         0.06      0  0.06    0.85  81.11      51.368   \n",
       "1   1     116  76.78            0      0     0   19.41   3.71  94.900.000   \n",
       "2   2      75  79.53        17.99    4.9   4.8     1.2    0.3        0.05   \n",
       "3   3  132.46  73.13        12.46   1.59  1.59    6.37   6.57        2.23   \n",
       "4   4  103.29  79.04        04.01  01.07  2.38   11.47   4.53        0.77   \n",
       "\n",
       "  cholesterol  ...  iron  folat  pantotenik  fosfor magnesium  cinko copper  \\\n",
       "0         215  ...  0.02      3        0.11      24         2   0.09     16   \n",
       "1          89  ...  0.76      4         1.1     174        20  02.05     66   \n",
       "2           0  ...  0.59     67  60.000.000      71        29   0.59   0.12   \n",
       "3       22.57  ...  0.98  15.53        0.39    79.5     21.38   1.36   0.15   \n",
       "4       28.62  ...  0.71   15.6         0.4   78.47     16.49   0.46   0.05   \n",
       "\n",
       "  selenium   manganese      Class  \n",
       "0        1           4  Hayvansal  \n",
       "1     21.8          14  Hayvansal  \n",
       "2      1.8  56.000.000   Bitkisel  \n",
       "3      5.2        0.24        Mix  \n",
       "4      8.5         0.1  Hayvansal  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"train.csv\")\n",
    "#data.Class = data.Class.map({'Hayvansal':0,'Bitkisel':1,'Mix':2})# RandomForestRegressor modeli için numeric etiketler kullanılır\n",
    "data.head()#ilk 5 satırdaki özellikler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>calorie</th>\n",
       "      <th>water</th>\n",
       "      <th>carbohydrate</th>\n",
       "      <th>fiber</th>\n",
       "      <th>sugar</th>\n",
       "      <th>protein</th>\n",
       "      <th>fat</th>\n",
       "      <th>sfat</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>...</th>\n",
       "      <th>niacin</th>\n",
       "      <th>iron</th>\n",
       "      <th>folat</th>\n",
       "      <th>pantotenik</th>\n",
       "      <th>fosfor</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>cinko</th>\n",
       "      <th>copper</th>\n",
       "      <th>selenium</th>\n",
       "      <th>manganese</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>121.85</td>\n",
       "      <td>74.92</td>\n",
       "      <td>2.96</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1.97</td>\n",
       "      <td>16.16</td>\n",
       "      <td>4.74</td>\n",
       "      <td>2.34</td>\n",
       "      <td>49.79</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.34</td>\n",
       "      <td>0.43</td>\n",
       "      <td>115.55</td>\n",
       "      <td>18.88</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.03</td>\n",
       "      <td>12.31</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>376</td>\n",
       "      <td>16.14</td>\n",
       "      <td>72.56</td>\n",
       "      <td>1.54</td>\n",
       "      <td>67.5</td>\n",
       "      <td>81.000.000</td>\n",
       "      <td>878.999.999</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>423.74</td>\n",
       "      <td>21.32</td>\n",
       "      <td>48.13</td>\n",
       "      <td>2.57</td>\n",
       "      <td>23.36</td>\n",
       "      <td>4.95</td>\n",
       "      <td>24.69</td>\n",
       "      <td>4.69</td>\n",
       "      <td>7.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.49</td>\n",
       "      <td>18.61</td>\n",
       "      <td>0.33</td>\n",
       "      <td>204.14</td>\n",
       "      <td>55.15</td>\n",
       "      <td>1.44</td>\n",
       "      <td>0.32</td>\n",
       "      <td>25.95</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>198.62</td>\n",
       "      <td>56.4</td>\n",
       "      <td>33.88</td>\n",
       "      <td>0.79</td>\n",
       "      <td>20.85</td>\n",
       "      <td>3.66</td>\n",
       "      <td>5.53</td>\n",
       "      <td>3.34</td>\n",
       "      <td>18.48</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>13.63</td>\n",
       "      <td>0.32</td>\n",
       "      <td>71.00</td>\n",
       "      <td>14.17</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>139</td>\n",
       "      <td>71.37</td>\n",
       "      <td>1.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.38</td>\n",
       "      <td>05.02</td>\n",
       "      <td>1.94</td>\n",
       "      <td>371</td>\n",
       "      <td>...</td>\n",
       "      <td>16.11</td>\n",
       "      <td>7.37</td>\n",
       "      <td>230</td>\n",
       "      <td>6.13</td>\n",
       "      <td>364.00</td>\n",
       "      <td>19.00</td>\n",
       "      <td>4.66</td>\n",
       "      <td>6.979</td>\n",
       "      <td>824.000.000</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID calorie  water carbohydrate fiber  sugar     protein          fat  sfat  \\\n",
       "0   0  121.85  74.92         2.96  0.82   1.97       16.16         4.74  2.34   \n",
       "1   1     376  16.14        72.56  1.54   67.5  81.000.000  878.999.999  0.75   \n",
       "2   2  423.74  21.32        48.13  2.57  23.36        4.95        24.69  4.69   \n",
       "3   3  198.62   56.4        33.88  0.79  20.85        3.66         5.53  3.34   \n",
       "4   4     139  71.37         1.78     0      0       20.38        05.02  1.94   \n",
       "\n",
       "  cholesterol  ...  niacin  iron  folat  pantotenik  fosfor  magnesium cinko  \\\n",
       "0       49.79  ...       0  0.66  11.34        0.43  115.55      18.88   0.7   \n",
       "1           0  ...       0  0.32      0           0   21.00       6.00   0.2   \n",
       "2        7.94  ...       0  1.49  18.61        0.33  204.14      55.15  1.44   \n",
       "3       18.48  ...       0  0.23  13.63        0.32   71.00      14.17  0.43   \n",
       "4         371  ...   16.11  7.37    230        6.13  364.00      19.00  4.66   \n",
       "\n",
       "  copper     selenium manganese  \n",
       "0   0.03        12.31      0.08  \n",
       "1    0.2          1.5       0.8  \n",
       "2   0.32        25.95      0.99  \n",
       "3   0.04          1.1      0.11  \n",
       "4  6.979  824.000.000       184  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2 = pd.read_csv(\"test.csv\")\n",
    "data2.head()#ilk 5 satırdaki özellikler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['Class'] #labels-etiketler\n",
    "X = data #Class etiketleri hariç diğer dataların bulunduğu dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>calorie</th>\n",
       "      <th>water</th>\n",
       "      <th>carbohydrate</th>\n",
       "      <th>fiber</th>\n",
       "      <th>sugar</th>\n",
       "      <th>protein</th>\n",
       "      <th>fat</th>\n",
       "      <th>sfat</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>...</th>\n",
       "      <th>iron</th>\n",
       "      <th>folat</th>\n",
       "      <th>pantotenik</th>\n",
       "      <th>fosfor</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>cinko</th>\n",
       "      <th>copper</th>\n",
       "      <th>selenium</th>\n",
       "      <th>manganese</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>717</td>\n",
       "      <td>17.94</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.85</td>\n",
       "      <td>81.11</td>\n",
       "      <td>51.368</td>\n",
       "      <td>215</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>3</td>\n",
       "      <td>0.11</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>0.09</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Hayvansal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>116</td>\n",
       "      <td>76.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.41</td>\n",
       "      <td>3.71</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>...</td>\n",
       "      <td>0.76</td>\n",
       "      <td>4</td>\n",
       "      <td>1.1</td>\n",
       "      <td>174</td>\n",
       "      <td>20</td>\n",
       "      <td>02.05</td>\n",
       "      <td>66</td>\n",
       "      <td>21.8</td>\n",
       "      <td>14</td>\n",
       "      <td>Hayvansal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>75</td>\n",
       "      <td>79.53</td>\n",
       "      <td>17.99</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.59</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>29</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0</td>\n",
       "      <td>Bitkisel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>132.46</td>\n",
       "      <td>73.13</td>\n",
       "      <td>12.46</td>\n",
       "      <td>1.59</td>\n",
       "      <td>1.59</td>\n",
       "      <td>6.37</td>\n",
       "      <td>6.57</td>\n",
       "      <td>2.23</td>\n",
       "      <td>22.57</td>\n",
       "      <td>...</td>\n",
       "      <td>0.98</td>\n",
       "      <td>15.53</td>\n",
       "      <td>0.39</td>\n",
       "      <td>79.5</td>\n",
       "      <td>21.38</td>\n",
       "      <td>1.36</td>\n",
       "      <td>0.15</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0.24</td>\n",
       "      <td>Mix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>103.29</td>\n",
       "      <td>79.04</td>\n",
       "      <td>04.01</td>\n",
       "      <td>01.07</td>\n",
       "      <td>2.38</td>\n",
       "      <td>11.47</td>\n",
       "      <td>4.53</td>\n",
       "      <td>0.77</td>\n",
       "      <td>28.62</td>\n",
       "      <td>...</td>\n",
       "      <td>0.71</td>\n",
       "      <td>15.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>78.47</td>\n",
       "      <td>16.49</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.05</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Hayvansal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2495</td>\n",
       "      <td>2495</td>\n",
       "      <td>502</td>\n",
       "      <td>4.23</td>\n",
       "      <td>64.8</td>\n",
       "      <td>1.1</td>\n",
       "      <td>48.25</td>\n",
       "      <td>4.91</td>\n",
       "      <td>24.85</td>\n",
       "      <td>18.96</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>105</td>\n",
       "      <td>27</td>\n",
       "      <td>01.06</td>\n",
       "      <td>197</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0</td>\n",
       "      <td>Mix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2496</td>\n",
       "      <td>2496</td>\n",
       "      <td>128</td>\n",
       "      <td>73.03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21.75</td>\n",
       "      <td>3.85</td>\n",
       "      <td>1.28</td>\n",
       "      <td>39</td>\n",
       "      <td>...</td>\n",
       "      <td>2.32</td>\n",
       "      <td>8</td>\n",
       "      <td>0.35</td>\n",
       "      <td>204</td>\n",
       "      <td>14</td>\n",
       "      <td>6.94</td>\n",
       "      <td>0</td>\n",
       "      <td>17.7</td>\n",
       "      <td>14</td>\n",
       "      <td>Hayvansal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2497</td>\n",
       "      <td>2497</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>27.99</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2.67</td>\n",
       "      <td>0.28</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>12</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0</td>\n",
       "      <td>Bitkisel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2498</td>\n",
       "      <td>2498</td>\n",
       "      <td>455</td>\n",
       "      <td>2.75</td>\n",
       "      <td>70.73</td>\n",
       "      <td>6.9</td>\n",
       "      <td>15.48</td>\n",
       "      <td>7.3</td>\n",
       "      <td>16.4</td>\n",
       "      <td>3.21</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.64</td>\n",
       "      <td>38</td>\n",
       "      <td>577</td>\n",
       "      <td>302</td>\n",
       "      <td>72</td>\n",
       "      <td>1.64</td>\n",
       "      <td>274</td>\n",
       "      <td>9.9</td>\n",
       "      <td>1.549</td>\n",
       "      <td>Bitkisel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2499</td>\n",
       "      <td>2499</td>\n",
       "      <td>79.81</td>\n",
       "      <td>80.36</td>\n",
       "      <td>14.65</td>\n",
       "      <td>1.33</td>\n",
       "      <td>0.84</td>\n",
       "      <td>2.72</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.03</td>\n",
       "      <td>2.53</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.43</td>\n",
       "      <td>54.77</td>\n",
       "      <td>17.91</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.12</td>\n",
       "      <td>Mix</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID calorie  water carbohydrate  fiber  sugar protein    fat    sfat  \\\n",
       "0        0     717  17.94         0.06      0   0.06    0.85  81.11  51.368   \n",
       "1        1     116  76.78            0      0      0   19.41   3.71       0   \n",
       "2        2      75  79.53        17.99    4.9    4.8     1.2    0.3    0.05   \n",
       "3        3  132.46  73.13        12.46   1.59   1.59    6.37   6.57    2.23   \n",
       "4        4  103.29  79.04        04.01  01.07   2.38   11.47   4.53    0.77   \n",
       "...    ...     ...    ...          ...    ...    ...     ...    ...     ...   \n",
       "2495  2495     502   4.23         64.8    1.1  48.25    4.91  24.85   18.96   \n",
       "2496  2496     128  73.03            0      0      0   21.75   3.85    1.28   \n",
       "2497  2497     129      0        27.99    0.4   0.05    2.67   0.28      77   \n",
       "2498  2498     455   2.75        70.73    6.9  15.48     7.3   16.4    3.21   \n",
       "2499  2499   79.81  80.36        14.65   1.33   0.84    2.72   1.35    0.03   \n",
       "\n",
       "     cholesterol  ...  iron  folat  pantotenik  fosfor magnesium  cinko  \\\n",
       "0            215  ...  0.02      3        0.11      24         2   0.09   \n",
       "1             89  ...  0.76      4         1.1     174        20  02.05   \n",
       "2              0  ...  0.59     67           0      71        29   0.59   \n",
       "3          22.57  ...  0.98  15.53        0.39    79.5     21.38   1.36   \n",
       "4          28.62  ...  0.71   15.6         0.4   78.47     16.49   0.46   \n",
       "...          ...  ...   ...    ...         ...     ...       ...    ...   \n",
       "2495           7  ...     0     26           0     105        27  01.06   \n",
       "2496          39  ...  2.32      8        0.35     204        14   6.94   \n",
       "2497           0  ...   1.2     58           0      43        12   0.49   \n",
       "2498           0  ...  2.64     38         577     302        72   1.64   \n",
       "2499        2.53  ...   0.3   8.14        0.43   54.77     17.91   0.29   \n",
       "\n",
       "     copper selenium manganese      Class  \n",
       "0        16        1         4  Hayvansal  \n",
       "1        66     21.8        14  Hayvansal  \n",
       "2      0.12      1.8         0   Bitkisel  \n",
       "3      0.15      5.2      0.24        Mix  \n",
       "4      0.05      8.5       0.1  Hayvansal  \n",
       "...     ...      ...       ...        ...  \n",
       "2495    197      4.3         0        Mix  \n",
       "2496      0     17.7        14  Hayvansal  \n",
       "2497      0      7.5         0   Bitkisel  \n",
       "2498    274      9.9     1.549   Bitkisel  \n",
       "2499   0.12      1.2      0.12        Mix  \n",
       "\n",
       "[2500 rows x 33 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "for columnName in data: #dataframe'in içindeki bütün kolonları tek tek dolaşır\n",
    "    \n",
    "    #x = kolondaki her bir variable \n",
    "    data[columnName] = data[columnName].apply(lambda x : 0 if (str(x).count('.') == 2) else x)#apply fonksiyonu kolonun bütün variablelarını kontrol eder, nokta sayısı fazlaysa datanın değerini 0 yapar\n",
    "    data[columnName] = data[columnName].apply(lambda x : 0 if ('Gram' in str(x)) else x)#apply 'Gram' değerlerini 0 yapar\n",
    "    data[columnName] = data[columnName].apply(lambda x : 0 if ('Mikrogram' in str(x)) else x) #apply 'Mikrogram' değerlerini 0 yapar\n",
    "   \n",
    "   \n",
    "\n",
    "  \n",
    "data    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-85b8cd6907e0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstyle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'whitegrid'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpalette\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"deep\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfont_scale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"figure.figsize\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m sns.distplot(\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Class'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm_hist\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkde\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m ).set(xlabel='Class', ylabel='P(Class)');#Class dağılımı-Distribution of Class\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\seaborn\\distributions.py\u001b[0m in \u001b[0;36mdistplot\u001b[1;34m(a, bins, hist, kde, rug, fit, hist_kws, kde_kws, rug_kws, fit_kws, color, vertical, norm_hist, axlabel, label, ax)\u001b[0m\n\u001b[0;32m    196\u001b[0m             \u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 198\u001b[1;33m             \u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m         \u001b[0mcolor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_color\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m         \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[1;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[0;32m     85\u001b[0m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mrcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mret\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mrcount\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'int'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns; sns.set(style=\"ticks\", color_codes=True)\n",
    "\n",
    "sns.set(style='whitegrid', palette=\"deep\", font_scale=1.1, rc={\"figure.figsize\": [8, 5]})\n",
    "sns.distplot(\n",
    "    data['Class'], norm_hist=False, kde=True\n",
    ").set(xlabel='Class', ylabel='P(Class)');#Class dağılımı-Distribution of Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>calorie</th>\n",
       "      <th>water</th>\n",
       "      <th>carbohydrate</th>\n",
       "      <th>fiber</th>\n",
       "      <th>sugar</th>\n",
       "      <th>protein</th>\n",
       "      <th>fat</th>\n",
       "      <th>sfat</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>...</th>\n",
       "      <th>niacin</th>\n",
       "      <th>iron</th>\n",
       "      <th>folat</th>\n",
       "      <th>pantotenik</th>\n",
       "      <th>fosfor</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>cinko</th>\n",
       "      <th>copper</th>\n",
       "      <th>selenium</th>\n",
       "      <th>manganese</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>121.85</td>\n",
       "      <td>74.92</td>\n",
       "      <td>2.96</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1.97</td>\n",
       "      <td>16.16</td>\n",
       "      <td>4.74</td>\n",
       "      <td>2.34</td>\n",
       "      <td>49.79</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.34</td>\n",
       "      <td>0.43</td>\n",
       "      <td>115.55</td>\n",
       "      <td>18.88</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.03</td>\n",
       "      <td>12.31</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>376</td>\n",
       "      <td>16.14</td>\n",
       "      <td>72.56</td>\n",
       "      <td>1.54</td>\n",
       "      <td>67.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>423.74</td>\n",
       "      <td>21.32</td>\n",
       "      <td>48.13</td>\n",
       "      <td>2.57</td>\n",
       "      <td>23.36</td>\n",
       "      <td>4.95</td>\n",
       "      <td>24.69</td>\n",
       "      <td>4.69</td>\n",
       "      <td>7.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.49</td>\n",
       "      <td>18.61</td>\n",
       "      <td>0.33</td>\n",
       "      <td>204.14</td>\n",
       "      <td>55.15</td>\n",
       "      <td>1.44</td>\n",
       "      <td>0.32</td>\n",
       "      <td>25.95</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>198.62</td>\n",
       "      <td>56.4</td>\n",
       "      <td>33.88</td>\n",
       "      <td>0.79</td>\n",
       "      <td>20.85</td>\n",
       "      <td>3.66</td>\n",
       "      <td>5.53</td>\n",
       "      <td>3.34</td>\n",
       "      <td>18.48</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>13.63</td>\n",
       "      <td>0.32</td>\n",
       "      <td>71.00</td>\n",
       "      <td>14.17</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>139</td>\n",
       "      <td>71.37</td>\n",
       "      <td>1.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.38</td>\n",
       "      <td>05.02</td>\n",
       "      <td>1.94</td>\n",
       "      <td>371</td>\n",
       "      <td>...</td>\n",
       "      <td>16.11</td>\n",
       "      <td>7.37</td>\n",
       "      <td>230</td>\n",
       "      <td>6.13</td>\n",
       "      <td>364.00</td>\n",
       "      <td>19.00</td>\n",
       "      <td>4.66</td>\n",
       "      <td>6.979</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>329</td>\n",
       "      <td>329</td>\n",
       "      <td>221</td>\n",
       "      <td>55.51</td>\n",
       "      <td>19.72</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.68</td>\n",
       "      <td>12.2</td>\n",
       "      <td>10.42</td>\n",
       "      <td>5.105</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>2.386</td>\n",
       "      <td>1.67</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>205.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>1.16</td>\n",
       "      <td>89</td>\n",
       "      <td>13.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>330</td>\n",
       "      <td>210</td>\n",
       "      <td>59.06</td>\n",
       "      <td>19.41</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.89</td>\n",
       "      <td>0</td>\n",
       "      <td>11.06</td>\n",
       "      <td>5.323</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>1.219</td>\n",
       "      <td>1.54</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>168.00</td>\n",
       "      <td>26.00</td>\n",
       "      <td>0.93</td>\n",
       "      <td>95</td>\n",
       "      <td>9.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>331</td>\n",
       "      <td>331</td>\n",
       "      <td>299</td>\n",
       "      <td>51.09</td>\n",
       "      <td>30</td>\n",
       "      <td>3.5</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>332</td>\n",
       "      <td>332</td>\n",
       "      <td>411</td>\n",
       "      <td>73.56</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.7</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>333</td>\n",
       "      <td>333</td>\n",
       "      <td>411</td>\n",
       "      <td>73.56</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.7</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>334 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID calorie  water carbohydrate fiber  sugar protein    fat   sfat  \\\n",
       "0      0  121.85  74.92         2.96  0.82   1.97   16.16   4.74   2.34   \n",
       "1      1     376  16.14        72.56  1.54   67.5       0      0   0.75   \n",
       "2      2  423.74  21.32        48.13  2.57  23.36    4.95  24.69   4.69   \n",
       "3      3  198.62   56.4        33.88  0.79  20.85    3.66   5.53   3.34   \n",
       "4      4     139  71.37         1.78     0      0   20.38  05.02   1.94   \n",
       "..   ...     ...    ...          ...   ...    ...     ...    ...    ...   \n",
       "329  329     221  55.51        19.72   2.4   1.68    12.2  10.42  5.105   \n",
       "330  330     210  59.06        19.41   2.9   1.89       0  11.06  5.323   \n",
       "331  331     299  51.09           30   3.5     29       5     13      7   \n",
       "332  332     411  73.56          8.1     0      0     5.7    8.1      0   \n",
       "333  333     411  73.56          8.1     0      0     5.7    8.1      0   \n",
       "\n",
       "    cholesterol  ...  niacin  iron  folat  pantotenik  fosfor  magnesium  \\\n",
       "0         49.79  ...       0  0.66  11.34        0.43  115.55      18.88   \n",
       "1             0  ...       0  0.32      0           0   21.00       6.00   \n",
       "2          7.94  ...       0  1.49  18.61        0.33  204.14      55.15   \n",
       "3         18.48  ...       0  0.23  13.63        0.32   71.00      14.17   \n",
       "4           371  ...   16.11  7.37    230        6.13  364.00      19.00   \n",
       "..          ...  ...     ...   ...    ...         ...     ...        ...   \n",
       "329          32  ...   2.386  1.67     46           0  205.00      25.00   \n",
       "330          22  ...   1.219  1.54     48           0  168.00      26.00   \n",
       "331           0  ...       0     0      0           0    0.00       0.00   \n",
       "332           0  ...       0     0      0           0    0.00       0.00   \n",
       "333           0  ...       0     0      0           0    0.00       0.00   \n",
       "\n",
       "    cinko copper selenium manganese  \n",
       "0     0.7   0.03    12.31      0.08  \n",
       "1     0.2    0.2      1.5       0.8  \n",
       "2    1.44   0.32    25.95      0.99  \n",
       "3    0.43   0.04      1.1      0.11  \n",
       "4    4.66  6.979        0       184  \n",
       "..    ...    ...      ...       ...  \n",
       "329  1.16     89     13.6         0  \n",
       "330  0.93     95      9.9         0  \n",
       "331     0      0        0         0  \n",
       "332     0      0        0         0  \n",
       "333     0      0        0         0  \n",
       "\n",
       "[334 rows x 32 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for columnName in data2:\n",
    "    \n",
    "    #x = kolondaki her bir variable \n",
    "    data2[columnName] = data2[columnName].apply(lambda x : 0 if (str(x).count('.') == 2) else x)#apply fonksiyonu kolonun bütün variablelarını kontrol eder, nokta sayısı fazlaysa datanın değerini 0 yapar\n",
    "    data2[columnName] = data2[columnName].apply(lambda x : 0 if ('Gram' in str(x)) else x)#apply 'Gram' değerlerini 0 yapar\n",
    "    data2[columnName] = data2[columnName].apply(lambda x : 0 if ('Mikrogram' in str(x)) else x) #apply 'Mikrogram' değerlerini 0 yapar\n",
    "   \n",
    "   \n",
    "   \n",
    "\n",
    "  \n",
    "data2    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = data.iloc[:,:-1]#iloc datayı böler ve iloc[:,:-1] dataframedeki en son kolon hariç bütün kolonları barındırır\n",
    "test=data2 #test datası"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LogisticRegression Modeli\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()#model tanımlanır\n",
    "model.fit(X, y)# model X(train data) ve y(labels-etiketler) ile eğitilir\n",
    "sc = model.score(X,y)#modelin % üzerinden tahmin doğruluğu hesaplanır\n",
    "print(sc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hayvansal' 'Mix' 'Bitkisel' 'Mix' 'Hayvansal' 'Bitkisel' 'Hayvansal'\n",
      " 'Bitkisel' 'Bitkisel' 'Bitkisel' 'Bitkisel' 'Hayvansal' 'Bitkisel'\n",
      " 'Bitkisel' 'Hayvansal' 'Mix' 'Bitkisel' 'Hayvansal' 'Bitkisel' 'Mix'\n",
      " 'Hayvansal' 'Bitkisel' 'Bitkisel' 'Bitkisel' 'Bitkisel' 'Bitkisel'\n",
      " 'Bitkisel' 'Bitkisel' 'Hayvansal' 'Mix' 'Hayvansal' 'Hayvansal'\n",
      " 'Bitkisel' 'Mix' 'Hayvansal' 'Bitkisel' 'Bitkisel' 'Bitkisel' 'Hayvansal'\n",
      " 'Bitkisel' 'Bitkisel' 'Hayvansal' 'Mix' 'Mix' 'Bitkisel' 'Bitkisel'\n",
      " 'Hayvansal' 'Bitkisel' 'Mix' 'Bitkisel' 'Hayvansal' 'Bitkisel' 'Bitkisel'\n",
      " 'Bitkisel' 'Bitkisel' 'Mix' 'Bitkisel' 'Hayvansal' 'Bitkisel' 'Bitkisel'\n",
      " 'Hayvansal' 'Hayvansal' 'Bitkisel' 'Bitkisel' 'Mix' 'Hayvansal'\n",
      " 'Bitkisel' 'Hayvansal' 'Bitkisel' 'Bitkisel' 'Bitkisel' 'Mix' 'Bitkisel'\n",
      " 'Bitkisel' 'Mix' 'Mix' 'Mix' 'Bitkisel' 'Mix' 'Bitkisel' 'Bitkisel'\n",
      " 'Hayvansal' 'Bitkisel' 'Bitkisel' 'Hayvansal' 'Bitkisel' 'Bitkisel'\n",
      " 'Bitkisel' 'Mix' 'Hayvansal' 'Bitkisel' 'Bitkisel' 'Bitkisel' 'Mix'\n",
      " 'Bitkisel' 'Hayvansal' 'Bitkisel' 'Hayvansal' 'Bitkisel' 'Hayvansal'\n",
      " 'Bitkisel' 'Hayvansal' 'Bitkisel' 'Bitkisel' 'Hayvansal' 'Hayvansal'\n",
      " 'Mix' 'Bitkisel' 'Hayvansal' 'Bitkisel' 'Hayvansal' 'Mix' 'Bitkisel'\n",
      " 'Bitkisel' 'Hayvansal' 'Bitkisel' 'Hayvansal' 'Hayvansal' 'Bitkisel'\n",
      " 'Hayvansal' 'Mix' 'Bitkisel' 'Bitkisel' 'Bitkisel' 'Hayvansal'\n",
      " 'Hayvansal' 'Mix' 'Mix' 'Bitkisel' 'Hayvansal' 'Bitkisel' 'Hayvansal'\n",
      " 'Hayvansal' 'Bitkisel' 'Bitkisel' 'Hayvansal' 'Bitkisel' 'Bitkisel'\n",
      " 'Bitkisel' 'Bitkisel' 'Hayvansal' 'Bitkisel' 'Bitkisel' 'Hayvansal'\n",
      " 'Hayvansal' 'Hayvansal' 'Bitkisel' 'Bitkisel' 'Bitkisel' 'Hayvansal'\n",
      " 'Bitkisel' 'Bitkisel' 'Mix' 'Bitkisel' 'Hayvansal' 'Bitkisel' 'Bitkisel'\n",
      " 'Bitkisel' 'Hayvansal' 'Hayvansal' 'Mix' 'Mix' 'Mix' 'Hayvansal'\n",
      " 'Bitkisel' 'Bitkisel' 'Hayvansal' 'Hayvansal' 'Bitkisel' 'Hayvansal'\n",
      " 'Hayvansal' 'Mix' 'Bitkisel' 'Mix' 'Bitkisel' 'Hayvansal' 'Bitkisel'\n",
      " 'Bitkisel' 'Bitkisel' 'Hayvansal' 'Bitkisel' 'Mix' 'Bitkisel' 'Bitkisel'\n",
      " 'Mix' 'Hayvansal' 'Bitkisel' 'Bitkisel' 'Hayvansal' 'Bitkisel' 'Bitkisel'\n",
      " 'Mix' 'Bitkisel' 'Hayvansal' 'Bitkisel' 'Bitkisel' 'Mix' 'Bitkisel' 'Mix'\n",
      " 'Bitkisel' 'Bitkisel' 'Bitkisel' 'Bitkisel' 'Bitkisel' 'Bitkisel'\n",
      " 'Hayvansal' 'Hayvansal' 'Hayvansal' 'Bitkisel' 'Bitkisel' 'Hayvansal'\n",
      " 'Bitkisel' 'Mix' 'Hayvansal' 'Hayvansal' 'Mix' 'Bitkisel' 'Bitkisel'\n",
      " 'Hayvansal' 'Hayvansal' 'Bitkisel' 'Mix' 'Bitkisel' 'Bitkisel' 'Bitkisel'\n",
      " 'Hayvansal' 'Bitkisel' 'Bitkisel' 'Hayvansal' 'Mix' 'Hayvansal'\n",
      " 'Hayvansal' 'Hayvansal' 'Bitkisel' 'Bitkisel' 'Hayvansal' 'Bitkisel'\n",
      " 'Hayvansal' 'Mix' 'Bitkisel' 'Hayvansal' 'Hayvansal' 'Hayvansal'\n",
      " 'Bitkisel' 'Mix' 'Bitkisel' 'Bitkisel' 'Hayvansal' 'Bitkisel' 'Hayvansal'\n",
      " 'Bitkisel' 'Bitkisel' 'Mix' 'Bitkisel' 'Bitkisel' 'Mix' 'Bitkisel'\n",
      " 'Bitkisel' 'Bitkisel' 'Hayvansal' 'Hayvansal' 'Mix' 'Hayvansal' 'Mix'\n",
      " 'Hayvansal' 'Hayvansal' 'Bitkisel' 'Mix' 'Mix' 'Bitkisel' 'Bitkisel'\n",
      " 'Bitkisel' 'Mix' 'Bitkisel' 'Mix' 'Hayvansal' 'Mix' 'Hayvansal' 'Mix'\n",
      " 'Mix' 'Hayvansal' 'Bitkisel' 'Hayvansal' 'Bitkisel' 'Bitkisel' 'Mix'\n",
      " 'Hayvansal' 'Hayvansal' 'Bitkisel' 'Bitkisel' 'Bitkisel' 'Bitkisel'\n",
      " 'Bitkisel' 'Bitkisel' 'Mix' 'Bitkisel' 'Bitkisel' 'Bitkisel' 'Hayvansal'\n",
      " 'Hayvansal' 'Bitkisel' 'Bitkisel' 'Bitkisel' 'Bitkisel' 'Hayvansal'\n",
      " 'Hayvansal' 'Bitkisel' 'Hayvansal' 'Bitkisel' 'Hayvansal' 'Bitkisel'\n",
      " 'Mix' 'Hayvansal' 'Mix' 'Bitkisel' 'Bitkisel' 'Bitkisel' 'Bitkisel' 'Mix'\n",
      " 'Hayvansal' 'Bitkisel' 'Bitkisel' 'Bitkisel' 'Mix' 'Hayvansal' 'Bitkisel'\n",
      " 'Hayvansal' 'Mix' 'Bitkisel' 'Mix' 'Bitkisel' 'Mix' 'Bitkisel' 'Bitkisel']\n"
     ]
    }
   ],
   "source": [
    "pred=model.predict(test)#test datası model üzerinde denenir ve model etiketsiz dataların etiketini tahmin eder\n",
    "print(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = pd.read_csv(\"test.csv\")\n",
    "submission = pd.DataFrame({\n",
    "        \"Id\": test[\"ID\"],\n",
    "        \"Prediction\": pred\n",
    "    })\n",
    "submission.to_csv('RegressionSimple.csv',header=True, index=False)#etiketlenmiş datalar csv'ye kaydedilir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Hayvansal'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-86f104607380>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#model tanımlanır\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#model X(train data) ve y(labels-etiketler) ile eğitilir\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#modelin % üzerinden tahmin doğruluğu hesaplanır\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"dtype\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mDOUBLE\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 278\u001b[1;33m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mascontiguousarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDOUBLE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    279\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mexpanded_class_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36mascontiguousarray\u001b[1;34m(a, dtype)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m     \"\"\"\n\u001b[1;32m--> 632\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'C'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mndmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Hayvansal'"
     ]
    }
   ],
   "source": [
    "# RandomForestRegressor modeli\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import linear_model\n",
    "\n",
    "cls = RandomForestRegressor(n_estimators=150)#model tanımlanır\n",
    "cls.fit(X, y)#model X(train data) ve y(labels-etiketler) ile eğitilir\n",
    "cls.score(X, y)#modelin % üzerinden tahmin doğruluğu hesaplanır"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This RandomForestRegressor instance is not fitted yet. Call 'fit' with appropriate arguments before using this method.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-95f1c93bdb34>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#test datası model üzerinde denenir ve model etiketsiz dataların etiketini tahmin eder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#0,1 ve 2 ye yakınlıklarına göre besinler sınıflandırılabilir\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    689\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m         \"\"\"\n\u001b[1;32m--> 691\u001b[1;33m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'estimators_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    692\u001b[0m         \u001b[1;31m# Check data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    693\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m    912\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    913\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mall_or_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mattributes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 914\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    915\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This RandomForestRegressor instance is not fitted yet. Call 'fit' with appropriate arguments before using this method."
     ]
    }
   ],
   "source": [
    "pred = cls.predict(test)#test datası model üzerinde denenir ve model etiketsiz dataların etiketini tahmin eder\n",
    "print(pred)#0,1 ve 2 ye yakınlıklarına göre besinler sınıflandırılabilir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Mix'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-2de0910b5b59>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcluster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mkmeans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcluster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKMeans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#model tanımı ve cluster(küme) sayısının belirlenmesi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mkmeans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#model eğitilir ve datalar kümelenir\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\k_means_.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    970\u001b[0m                 \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy_x\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    971\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malgorithm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 972\u001b[1;33m                 return_n_iter=True)\n\u001b[0m\u001b[0;32m    973\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    974\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\k_means_.py\u001b[0m in \u001b[0;36mk_means\u001b[1;34m(X, n_clusters, sample_weight, init, precompute_distances, n_init, max_iter, verbose, tol, random_state, copy_x, n_jobs, algorithm, return_n_iter)\u001b[0m\n\u001b[0;32m    310\u001b[0m     \u001b[0morder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"C\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcopy_x\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m     X = check_array(X, accept_sparse='csr', dtype=[np.float64, np.float32],\n\u001b[1;32m--> 312\u001b[1;33m                     order=order, copy=copy_x)\n\u001b[0m\u001b[0;32m    313\u001b[0m     \u001b[1;31m# verify that the number of samples given is larger than k\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mn_clusters\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    494\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 496\u001b[1;33m                 \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    497\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m     \"\"\"\n\u001b[1;32m--> 538\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Mix'"
     ]
    }
   ],
   "source": [
    "#Kmeans Cluster Modeli\n",
    "from sklearn import cluster\n",
    "kmeans = cluster.KMeans(n_clusters=20)#model tanımı ve cluster(küme) sayısının belirlenmesi\n",
    "kmeans.fit(data)#model eğitilir ve datalar kümelenir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
